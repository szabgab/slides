# Exercise: Web crawler

* Build a crawler that, given a single URL and a number N will visit N pages linked from that page. (Maybe need to also get to the links of the links etc.)
* You can use [HTML::TreeBuilder::XPath](https://metacpan.org/pod/HTML::TreeBuilder::XPath) to extract the links from the html document.
* It is probably better to allow only the main process to fork.


